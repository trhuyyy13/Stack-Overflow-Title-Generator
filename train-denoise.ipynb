{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e064c4c0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-05T13:43:54.524904Z",
     "iopub.status.busy": "2025-06-05T13:43:54.524644Z",
     "iopub.status.idle": "2025-06-05T13:44:00.993471Z",
     "shell.execute_reply": "2025-06-05T13:44:00.992499Z"
    },
    "papermill": {
     "duration": 6.473401,
     "end_time": "2025-06-05T13:44:00.995053",
     "exception": false,
     "start_time": "2025-06-05T13:43:54.521652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b704f1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T13:44:01.000139Z",
     "iopub.status.busy": "2025-06-05T13:44:00.999884Z",
     "iopub.status.idle": "2025-06-05T13:44:01.728299Z",
     "shell.execute_reply": "2025-06-05T13:44:01.727732Z"
    },
    "papermill": {
     "duration": 0.732329,
     "end_time": "2025-06-05T13:44:01.729703",
     "exception": false,
     "start_time": "2025-06-05T13:44:00.997374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Thêm thêm Secret HF_TOKEN trong \"Add-ons\" => \"Secrets\" => Add Secret với label là \"HF_TOKEN\" và value là token của bạn (để chế độ WRITE trong HuggingFace)\n",
    "secret_label = \"HF_TOKEN\"\n",
    "secret_value = UserSecretsClient().get_secret(secret_label)\n",
    "login(token=secret_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c485a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T13:44:01.734624Z",
     "iopub.status.busy": "2025-06-05T13:44:01.734151Z",
     "iopub.status.idle": "2025-06-05T13:44:01.740223Z",
     "shell.execute_reply": "2025-06-05T13:44:01.739507Z"
    },
    "papermill": {
     "duration": 0.009553,
     "end_time": "2025-06-05T13:44:01.741229",
     "exception": false,
     "start_time": "2025-06-05T13:44:01.731676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import importlib\n",
    "import transformers\n",
    "importlib.reload(transformers)\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, Seq2SeqTrainingArguments\n",
    ")\n",
    "from datasets.utils.logging import disable_progress_bar, enable_progress_bar\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--task\", type=str, choices=[\"gen\", \"denoise\"], required=True)\n",
    "parser.add_argument(\"--train_file\", type=str, required=True)\n",
    "parser.add_argument(\"--valid_file\", type=str, required=True)\n",
    "parser.add_argument(\"--output_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--init_model\", type=str, default=\"Salesforce/codet5-base\")\n",
    "parser.add_argument(\"--num_train_epochs\", type=int, default=None)\n",
    "parser.add_argument(\"--push_to_hub\", action=\"store_true\")\n",
    "parser.add_argument(\"--hub_model_id\", type=str, default=None)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"Loading model from: {args.init_model}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.init_model)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(args.init_model)\n",
    "\n",
    "if args.task == \"denoise\":\n",
    "    default_epochs = 3\n",
    "    target_max_len = 64\n",
    "elif args.task == \"gen\":\n",
    "    default_epochs = 4\n",
    "    target_max_len = 64\n",
    "\n",
    "num_epochs = args.num_train_epochs if args.num_train_epochs else default_epochs\n",
    "\n",
    "print(f\"Loading data from: {args.train_file}\")\n",
    "df_train = pd.read_csv(args.train_file)\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "\n",
    "print(f\"Loading data from: {args.valid_file}\")\n",
    "df_valid = pd.read_csv(args.valid_file)\n",
    "dataset_valid = Dataset.from_pandas(df_valid)\n",
    "\n",
    "def tokenize(example):\n",
    "    model_input = tokenizer(\n",
    "        example[\"content\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        example[\"title\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=target_max_len\n",
    "    )\n",
    "    model_input[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_input\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "disable_progress_bar()\n",
    "tokenized_dataset_train = dataset_train.map(tokenize)\n",
    "tokenized_dataset_valid = dataset_valid.map(tokenize)\n",
    "enable_progress_bar()\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [\"\\n\".join(pred.strip().split(\". \")) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(label.strip().split(\". \")) for label in decoded_labels]\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(pred, ref) for pred, ref in zip(decoded_preds, decoded_labels)]\n",
    "\n",
    "    rouge1_f1 = sum(s[\"rouge1\"].fmeasure for s in scores) / len(scores)\n",
    "    rouge2_f1 = sum(s[\"rouge2\"].fmeasure for s in scores) / len(scores)\n",
    "    rougeL_f1 = sum(s[\"rougeL\"].fmeasure for s in scores) / len(scores)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge1_f1,\n",
    "        \"rouge2\": rouge2_f1,\n",
    "        \"rougeL\": rougeL_f1,\n",
    "    }\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=args.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=14,\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_accumulation_steps=4,\n",
    "    generation_max_length=64,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=f\"{args.output_dir}/logs\",\n",
    "    logging_steps=100,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    learning_rate=3e-5,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=args.push_to_hub,\n",
    "    hub_model_id=args.hub_model_id,\n",
    "    hub_strategy=\"end\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(f\"Starting training for task: {args.task} | Epochs: {num_epochs}\")\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "\n",
    "if args.push_to_hub:\n",
    "    trainer.push_to_hub()\n",
    "    print(f\"Model pushed to: https://huggingface.co/{args.hub_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46377a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T13:44:01.745429Z",
     "iopub.status.busy": "2025-06-05T13:44:01.745245Z",
     "iopub.status.idle": "2025-06-05T23:57:40.991143Z",
     "shell.execute_reply": "2025-06-05T23:57:40.990385Z"
    },
    "papermill": {
     "duration": 36819.249488,
     "end_time": "2025-06-05T23:57:40.992524",
     "exception": false,
     "start_time": "2025-06-05T13:44:01.743036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:44:18.878148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749131059.061628      52 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749131059.115279      52 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Loading model from: Salesforce/codet5-base\r\n",
      "tokenizer_config.json: 100%|███████████████| 1.48k/1.48k [00:00<00:00, 11.1MB/s]\r\n",
      "vocab.json: 100%|████████████████████████████| 703k/703k [00:00<00:00, 1.70MB/s]\r\n",
      "merges.txt: 100%|████████████████████████████| 294k/294k [00:00<00:00, 33.4MB/s]\r\n",
      "added_tokens.json: 100%|█████████████████████| 2.00/2.00 [00:00<00:00, 12.8kB/s]\r\n",
      "special_tokens_map.json: 100%|█████████████| 12.5k/12.5k [00:00<00:00, 42.6MB/s]\r\n",
      "config.json: 100%|█████████████████████████| 1.57k/1.57k [00:00<00:00, 11.1MB/s]\r\n",
      "pytorch_model.bin: 100%|█████████████████████| 892M/892M [00:11<00:00, 76.2MB/s]\r\n",
      "model.safetensors:  12%|██▌                   | 105M/892M [00:00<00:03, 235MB/s]Loading data from: /kaggle/input/denoise-filler-v3/train_denoise.csv\r\n",
      "model.safetensors: 100%|██████████████████████| 892M/892M [00:02<00:00, 299MB/s]\r\n",
      "Loading data from: /kaggle/input/denoise-filler-v3/valid_denoise.csv\r\n",
      "Tokenizing...\r\n",
      "/kaggle/working/train.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\r\n",
      "  trainer = Trainer(\r\n",
      "Starting training for task: denoise | Epochs: 2\r\n",
      "  0%|                                                 | 0/33630 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\r\n",
      "{'loss': 0.6596, 'grad_norm': 1.022255778312683, 'learning_rate': 2.991347011596789e-05, 'epoch': 0.01}\r\n",
      "{'loss': 0.1347, 'grad_norm': 0.631038248538971, 'learning_rate': 2.9824264049955398e-05, 'epoch': 0.01}\r\n",
      "{'loss': 0.1381, 'grad_norm': 0.5795683264732361, 'learning_rate': 2.973505798394291e-05, 'epoch': 0.02}\r\n",
      "{'loss': 0.1271, 'grad_norm': 0.7004238963127136, 'learning_rate': 2.964585191793042e-05, 'epoch': 0.02}\r\n",
      "{'loss': 0.1238, 'grad_norm': 0.5323605537414551, 'learning_rate': 2.9556645851917933e-05, 'epoch': 0.03}\r\n",
      "{'loss': 0.1279, 'grad_norm': 0.42921796441078186, 'learning_rate': 2.946743978590544e-05, 'epoch': 0.04}\r\n",
      "{'loss': 0.1207, 'grad_norm': 0.5735310316085815, 'learning_rate': 2.9378233719892953e-05, 'epoch': 0.04}\r\n",
      "{'loss': 0.1259, 'grad_norm': 0.31499412655830383, 'learning_rate': 2.9289027653880464e-05, 'epoch': 0.05}\r\n",
      "{'loss': 0.1171, 'grad_norm': 0.6145806312561035, 'learning_rate': 2.9199821587867976e-05, 'epoch': 0.05}\r\n",
      "{'loss': 0.1126, 'grad_norm': 0.3647456169128418, 'learning_rate': 2.9110615521855487e-05, 'epoch': 0.06}\r\n",
      "{'loss': 0.1147, 'grad_norm': 0.4437924325466156, 'learning_rate': 2.9021409455842996e-05, 'epoch': 0.07}\r\n",
      "{'loss': 0.1183, 'grad_norm': 0.5400431752204895, 'learning_rate': 2.893220338983051e-05, 'epoch': 0.07}\r\n",
      "{'loss': 0.114, 'grad_norm': 0.6102492809295654, 'learning_rate': 2.884299732381802e-05, 'epoch': 0.08}\r\n",
      "{'loss': 0.114, 'grad_norm': 0.4976485073566437, 'learning_rate': 2.875379125780553e-05, 'epoch': 0.08}\r\n",
      "{'loss': 0.1127, 'grad_norm': 0.4622468948364258, 'learning_rate': 2.8664585191793042e-05, 'epoch': 0.09}\r\n",
      "{'loss': 0.1114, 'grad_norm': 2.530038833618164, 'learning_rate': 2.8575379125780554e-05, 'epoch': 0.1}\r\n",
      "{'loss': 0.1079, 'grad_norm': 0.35920101404190063, 'learning_rate': 2.8486173059768062e-05, 'epoch': 0.1}\r\n",
      "{'loss': 0.1088, 'grad_norm': 0.40436461567878723, 'learning_rate': 2.8396966993755577e-05, 'epoch': 0.11}\r\n",
      "{'loss': 0.1073, 'grad_norm': 0.4919530749320984, 'learning_rate': 2.8307760927743086e-05, 'epoch': 0.11}\r\n",
      "{'loss': 0.1093, 'grad_norm': 0.34518787264823914, 'learning_rate': 2.8218554861730597e-05, 'epoch': 0.12}\r\n",
      "{'loss': 0.1144, 'grad_norm': 0.3598887324333191, 'learning_rate': 2.812934879571811e-05, 'epoch': 0.12}\r\n",
      "{'loss': 0.1078, 'grad_norm': 0.45866620540618896, 'learning_rate': 2.804014272970562e-05, 'epoch': 0.13}\r\n",
      "{'loss': 0.1119, 'grad_norm': 0.49321311712265015, 'learning_rate': 2.7950936663693132e-05, 'epoch': 0.14}\r\n",
      "{'loss': 0.1057, 'grad_norm': 0.4187277555465698, 'learning_rate': 2.7861730597680644e-05, 'epoch': 0.14}\r\n",
      "{'loss': 0.1092, 'grad_norm': 0.41404989361763, 'learning_rate': 2.7772524531668152e-05, 'epoch': 0.15}\r\n",
      "{'loss': 0.1062, 'grad_norm': 0.281467080116272, 'learning_rate': 2.7683318465655667e-05, 'epoch': 0.15}\r\n",
      "{'loss': 0.1085, 'grad_norm': 0.442488431930542, 'learning_rate': 2.7594112399643175e-05, 'epoch': 0.16}\r\n",
      "{'loss': 0.1111, 'grad_norm': 0.43708351254463196, 'learning_rate': 2.7504906333630687e-05, 'epoch': 0.17}\r\n",
      "{'loss': 0.106, 'grad_norm': 0.3790754973888397, 'learning_rate': 2.74157002676182e-05, 'epoch': 0.17}\r\n",
      "{'loss': 0.1088, 'grad_norm': 0.5468198657035828, 'learning_rate': 2.732649420160571e-05, 'epoch': 0.18}\r\n",
      "{'loss': 0.1077, 'grad_norm': 0.4806823134422302, 'learning_rate': 2.723728813559322e-05, 'epoch': 0.18}\r\n",
      "{'loss': 0.1021, 'grad_norm': 0.4752679467201233, 'learning_rate': 2.7148082069580734e-05, 'epoch': 0.19}\r\n",
      "{'loss': 0.1046, 'grad_norm': 0.34572499990463257, 'learning_rate': 2.7058876003568242e-05, 'epoch': 0.2}\r\n",
      "{'loss': 0.1053, 'grad_norm': 0.49802497029304504, 'learning_rate': 2.6969669937555757e-05, 'epoch': 0.2}\r\n",
      "{'loss': 0.1034, 'grad_norm': 0.37894874811172485, 'learning_rate': 2.6880463871543265e-05, 'epoch': 0.21}\r\n",
      "{'loss': 0.1001, 'grad_norm': 0.43151769042015076, 'learning_rate': 2.6791257805530777e-05, 'epoch': 0.21}\r\n",
      "{'loss': 0.1037, 'grad_norm': 0.4042331874370575, 'learning_rate': 2.670205173951829e-05, 'epoch': 0.22}\r\n",
      "{'loss': 0.1009, 'grad_norm': 0.40189072489738464, 'learning_rate': 2.66128456735058e-05, 'epoch': 0.23}\r\n",
      "{'loss': 0.1039, 'grad_norm': 0.49306726455688477, 'learning_rate': 2.652363960749331e-05, 'epoch': 0.23}\r\n",
      "{'loss': 0.1046, 'grad_norm': 0.4276149272918701, 'learning_rate': 2.6434433541480823e-05, 'epoch': 0.24}\r\n",
      "{'loss': 0.1074, 'grad_norm': 0.4651205837726593, 'learning_rate': 2.6345227475468332e-05, 'epoch': 0.24}\r\n",
      "{'loss': 0.1069, 'grad_norm': 0.38045021891593933, 'learning_rate': 2.6256021409455843e-05, 'epoch': 0.25}\r\n",
      "{'loss': 0.0978, 'grad_norm': 0.38804519176483154, 'learning_rate': 2.6166815343443355e-05, 'epoch': 0.26}\r\n",
      "{'loss': 0.1039, 'grad_norm': 0.5837052464485168, 'learning_rate': 2.6077609277430867e-05, 'epoch': 0.26}\r\n",
      "{'loss': 0.1007, 'grad_norm': 0.523682177066803, 'learning_rate': 2.598840321141838e-05, 'epoch': 0.27}\r\n",
      "{'loss': 0.1066, 'grad_norm': 0.4783298075199127, 'learning_rate': 2.589919714540589e-05, 'epoch': 0.27}\r\n",
      "{'loss': 0.1007, 'grad_norm': 0.38505470752716064, 'learning_rate': 2.5809991079393398e-05, 'epoch': 0.28}\r\n",
      "{'loss': 0.1043, 'grad_norm': 0.4354475140571594, 'learning_rate': 2.5720785013380913e-05, 'epoch': 0.29}\r\n",
      "{'loss': 0.1017, 'grad_norm': 0.3170659840106964, 'learning_rate': 2.563157894736842e-05, 'epoch': 0.29}\r\n",
      "{'loss': 0.1023, 'grad_norm': 0.5657841563224792, 'learning_rate': 2.5542372881355933e-05, 'epoch': 0.3}\r\n",
      "{'loss': 0.1003, 'grad_norm': 0.39242082834243774, 'learning_rate': 2.5453166815343445e-05, 'epoch': 0.3}\r\n",
      "{'loss': 0.1056, 'grad_norm': 0.351118266582489, 'learning_rate': 2.5363960749330957e-05, 'epoch': 0.31}\r\n",
      "{'loss': 0.1047, 'grad_norm': 0.3453187346458435, 'learning_rate': 2.5274754683318465e-05, 'epoch': 0.32}\r\n",
      "{'loss': 0.0989, 'grad_norm': 0.3671216368675232, 'learning_rate': 2.518554861730598e-05, 'epoch': 0.32}\r\n",
      "{'loss': 0.1046, 'grad_norm': 0.344762921333313, 'learning_rate': 2.5096342551293488e-05, 'epoch': 0.33}\r\n",
      "{'loss': 0.1003, 'grad_norm': 0.36734068393707275, 'learning_rate': 2.5007136485281e-05, 'epoch': 0.33}\r\n",
      "{'loss': 0.097, 'grad_norm': 0.3819233775138855, 'learning_rate': 2.491793041926851e-05, 'epoch': 0.34}\r\n",
      "{'loss': 0.1019, 'grad_norm': 0.46417945623397827, 'learning_rate': 2.482872435325602e-05, 'epoch': 0.34}\r\n",
      "{'loss': 0.1018, 'grad_norm': 0.35236284136772156, 'learning_rate': 2.4739518287243535e-05, 'epoch': 0.35}\r\n",
      "{'loss': 0.0971, 'grad_norm': 0.2921279966831207, 'learning_rate': 2.4650312221231043e-05, 'epoch': 0.36}\r\n",
      "{'loss': 0.1029, 'grad_norm': 0.27500951290130615, 'learning_rate': 2.4561106155218555e-05, 'epoch': 0.36}\r\n",
      "{'loss': 0.1036, 'grad_norm': 0.4576169550418854, 'learning_rate': 2.4471900089206066e-05, 'epoch': 0.37}\r\n",
      "{'loss': 0.0989, 'grad_norm': 0.4034126400947571, 'learning_rate': 2.4382694023193578e-05, 'epoch': 0.37}\r\n",
      "{'loss': 0.0973, 'grad_norm': 0.41297677159309387, 'learning_rate': 2.4293487957181086e-05, 'epoch': 0.38}\r\n",
      "{'loss': 0.1036, 'grad_norm': 0.41414397954940796, 'learning_rate': 2.42042818911686e-05, 'epoch': 0.39}\r\n",
      "{'loss': 0.1007, 'grad_norm': 0.4401874840259552, 'learning_rate': 2.411507582515611e-05, 'epoch': 0.39}\r\n",
      "{'loss': 0.0992, 'grad_norm': 0.3930208086967468, 'learning_rate': 2.402586975914362e-05, 'epoch': 0.4}\r\n",
      "{'loss': 0.1001, 'grad_norm': 0.3989952802658081, 'learning_rate': 2.3936663693131133e-05, 'epoch': 0.4}\r\n",
      "{'loss': 0.1016, 'grad_norm': 0.6849924921989441, 'learning_rate': 2.3847457627118644e-05, 'epoch': 0.41}\r\n",
      "{'loss': 0.102, 'grad_norm': 0.5042812824249268, 'learning_rate': 2.3758251561106156e-05, 'epoch': 0.42}\r\n",
      "{'loss': 0.0986, 'grad_norm': 0.48490843176841736, 'learning_rate': 2.3669045495093668e-05, 'epoch': 0.42}\r\n",
      "{'loss': 0.0988, 'grad_norm': 0.3520064055919647, 'learning_rate': 2.3579839429081176e-05, 'epoch': 0.43}\r\n",
      "{'loss': 0.1002, 'grad_norm': 0.3514692485332489, 'learning_rate': 2.349063336306869e-05, 'epoch': 0.43}\r\n",
      "{'loss': 0.0986, 'grad_norm': 0.36925363540649414, 'learning_rate': 2.34014272970562e-05, 'epoch': 0.44}\r\n",
      "{'loss': 0.097, 'grad_norm': 0.37227773666381836, 'learning_rate': 2.331222123104371e-05, 'epoch': 0.45}\r\n",
      "{'loss': 0.0966, 'grad_norm': 0.3290293514728546, 'learning_rate': 2.3223015165031223e-05, 'epoch': 0.45}\r\n",
      "{'loss': 0.1, 'grad_norm': 0.3952886462211609, 'learning_rate': 2.3133809099018734e-05, 'epoch': 0.46}\r\n",
      "{'loss': 0.0955, 'grad_norm': 0.4568582773208618, 'learning_rate': 2.3044603033006242e-05, 'epoch': 0.46}\r\n",
      "{'loss': 0.0982, 'grad_norm': 0.483671635389328, 'learning_rate': 2.2955396966993758e-05, 'epoch': 0.47}\r\n",
      "{'loss': 0.0961, 'grad_norm': 0.3607867658138275, 'learning_rate': 2.2866190900981266e-05, 'epoch': 0.48}\r\n",
      "{'loss': 0.0984, 'grad_norm': 0.38010871410369873, 'learning_rate': 2.277698483496878e-05, 'epoch': 0.48}\r\n",
      "{'loss': 0.1019, 'grad_norm': 0.3525303304195404, 'learning_rate': 2.268777876895629e-05, 'epoch': 0.49}\r\n",
      "{'loss': 0.0958, 'grad_norm': 0.36049720644950867, 'learning_rate': 2.25985727029438e-05, 'epoch': 0.49}\r\n",
      "{'loss': 0.0975, 'grad_norm': 0.4496109187602997, 'learning_rate': 2.2509366636931312e-05, 'epoch': 0.5}\r\n",
      "{'loss': 0.0954, 'grad_norm': 0.48408809304237366, 'learning_rate': 2.2420160570918824e-05, 'epoch': 0.51}\r\n",
      "{'loss': 0.0959, 'grad_norm': 0.29985859990119934, 'learning_rate': 2.2330954504906332e-05, 'epoch': 0.51}\r\n",
      "{'loss': 0.0953, 'grad_norm': 0.4034804403781891, 'learning_rate': 2.2241748438893847e-05, 'epoch': 0.52}\r\n",
      "{'loss': 0.0947, 'grad_norm': 0.2812824547290802, 'learning_rate': 2.215343443354148e-05, 'epoch': 0.52}\r\n",
      "{'loss': 0.0929, 'grad_norm': 0.4104873836040497, 'learning_rate': 2.2064228367528993e-05, 'epoch': 0.53}\r\n",
      "{'loss': 0.0972, 'grad_norm': 0.26013317704200745, 'learning_rate': 2.1975022301516505e-05, 'epoch': 0.54}\r\n",
      "{'loss': 0.0961, 'grad_norm': 0.38500356674194336, 'learning_rate': 2.1885816235504016e-05, 'epoch': 0.54}\r\n",
      "{'loss': 0.095, 'grad_norm': 0.42061465978622437, 'learning_rate': 2.1796610169491528e-05, 'epoch': 0.55}\r\n",
      "{'loss': 0.0938, 'grad_norm': 0.4206158518791199, 'learning_rate': 2.1707404103479036e-05, 'epoch': 0.55}\r\n",
      "{'loss': 0.096, 'grad_norm': 0.5036799907684326, 'learning_rate': 2.1618198037466548e-05, 'epoch': 0.56}\r\n",
      "{'loss': 0.0965, 'grad_norm': 0.34528568387031555, 'learning_rate': 2.152899197145406e-05, 'epoch': 0.56}\r\n",
      "{'loss': 0.0983, 'grad_norm': 0.4206385910511017, 'learning_rate': 2.1439785905441568e-05, 'epoch': 0.57}\r\n",
      "{'loss': 0.0992, 'grad_norm': 0.42912474274635315, 'learning_rate': 2.1350579839429083e-05, 'epoch': 0.58}\r\n",
      "{'loss': 0.0962, 'grad_norm': 0.274710476398468, 'learning_rate': 2.126137377341659e-05, 'epoch': 0.58}\r\n",
      "{'loss': 0.0964, 'grad_norm': 0.3651237189769745, 'learning_rate': 2.1172167707404103e-05, 'epoch': 0.59}\r\n",
      "{'loss': 0.0934, 'grad_norm': 0.3216508626937866, 'learning_rate': 2.1082961641391614e-05, 'epoch': 0.59}\r\n",
      "{'loss': 0.0969, 'grad_norm': 0.41389909386634827, 'learning_rate': 2.0993755575379126e-05, 'epoch': 0.6}\r\n",
      "{'loss': 0.0958, 'grad_norm': 0.3457793891429901, 'learning_rate': 2.0904549509366638e-05, 'epoch': 0.61}\r\n",
      "{'loss': 0.0971, 'grad_norm': 0.3633078634738922, 'learning_rate': 2.081534344335415e-05, 'epoch': 0.61}\r\n",
      "{'loss': 0.0936, 'grad_norm': 0.3239329755306244, 'learning_rate': 2.0726137377341658e-05, 'epoch': 0.62}\r\n",
      "{'loss': 0.0945, 'grad_norm': 0.36061543226242065, 'learning_rate': 2.0636931311329173e-05, 'epoch': 0.62}\r\n",
      "{'loss': 0.0935, 'grad_norm': 0.3756546974182129, 'learning_rate': 2.054772524531668e-05, 'epoch': 0.63}\r\n",
      "{'loss': 0.0926, 'grad_norm': 0.26543259620666504, 'learning_rate': 2.0458519179304192e-05, 'epoch': 0.64}\r\n",
      "{'loss': 0.0944, 'grad_norm': 0.29939910769462585, 'learning_rate': 2.0369313113291704e-05, 'epoch': 0.64}\r\n",
      "{'loss': 0.0923, 'grad_norm': 0.33057156205177307, 'learning_rate': 2.0280107047279216e-05, 'epoch': 0.65}\r\n",
      "{'loss': 0.0937, 'grad_norm': 0.46409010887145996, 'learning_rate': 2.0190900981266724e-05, 'epoch': 0.65}\r\n",
      "{'loss': 0.095, 'grad_norm': 0.6322264671325684, 'learning_rate': 2.010169491525424e-05, 'epoch': 0.66}\r\n",
      "{'loss': 0.0956, 'grad_norm': 0.25640255212783813, 'learning_rate': 2.0012488849241747e-05, 'epoch': 0.67}\r\n",
      "{'loss': 0.0933, 'grad_norm': 0.39723333716392517, 'learning_rate': 1.9923282783229262e-05, 'epoch': 0.67}\r\n",
      "{'loss': 0.0968, 'grad_norm': 0.29690903425216675, 'learning_rate': 1.983407671721677e-05, 'epoch': 0.68}\r\n",
      "{'loss': 0.0947, 'grad_norm': 0.662220299243927, 'learning_rate': 1.9744870651204282e-05, 'epoch': 0.68}\r\n",
      "{'loss': 0.0976, 'grad_norm': 0.3347727060317993, 'learning_rate': 1.9655664585191794e-05, 'epoch': 0.69}\r\n",
      "{'loss': 0.0946, 'grad_norm': 0.3557988107204437, 'learning_rate': 1.9566458519179306e-05, 'epoch': 0.7}\r\n",
      "{'loss': 0.0922, 'grad_norm': 0.30163416266441345, 'learning_rate': 1.9477252453166814e-05, 'epoch': 0.7}\r\n",
      "{'loss': 0.0923, 'grad_norm': 0.3058162331581116, 'learning_rate': 1.938893844781445e-05, 'epoch': 0.71}\r\n",
      "{'loss': 0.0953, 'grad_norm': 0.39663994312286377, 'learning_rate': 1.9299732381801963e-05, 'epoch': 0.71}\r\n",
      "{'loss': 0.0946, 'grad_norm': 0.42623698711395264, 'learning_rate': 1.9210526315789474e-05, 'epoch': 0.72}\r\n",
      "{'loss': 0.0936, 'grad_norm': 0.35996606945991516, 'learning_rate': 1.9121320249776986e-05, 'epoch': 0.73}\r\n",
      "{'loss': 0.094, 'grad_norm': 0.4460340738296509, 'learning_rate': 1.9032114183764498e-05, 'epoch': 0.73}\r\n",
      "{'loss': 0.0947, 'grad_norm': 0.3220258057117462, 'learning_rate': 1.894290811775201e-05, 'epoch': 0.74}\r\n",
      "{'loss': 0.0919, 'grad_norm': 0.33559656143188477, 'learning_rate': 1.8853702051739518e-05, 'epoch': 0.74}\r\n",
      "{'loss': 0.0912, 'grad_norm': 0.45317283272743225, 'learning_rate': 1.8764495985727033e-05, 'epoch': 0.75}\r\n",
      "{'loss': 0.0929, 'grad_norm': 0.6316466331481934, 'learning_rate': 1.867528991971454e-05, 'epoch': 0.76}\r\n",
      "{'loss': 0.0953, 'grad_norm': 0.40633106231689453, 'learning_rate': 1.8586083853702053e-05, 'epoch': 0.76}\r\n",
      "{'loss': 0.093, 'grad_norm': 0.35267284512519836, 'learning_rate': 1.8496877787689564e-05, 'epoch': 0.77}\r\n",
      "{'loss': 0.0959, 'grad_norm': 0.4172988831996918, 'learning_rate': 1.8407671721677073e-05, 'epoch': 0.77}\r\n",
      "{'loss': 0.0884, 'grad_norm': 0.28371870517730713, 'learning_rate': 1.8318465655664584e-05, 'epoch': 0.78}\r\n",
      "{'loss': 0.0882, 'grad_norm': 0.42084425687789917, 'learning_rate': 1.8229259589652096e-05, 'epoch': 0.79}\r\n",
      "{'loss': 0.0972, 'grad_norm': 0.37076684832572937, 'learning_rate': 1.8140053523639608e-05, 'epoch': 0.79}\r\n",
      "{'loss': 0.0903, 'grad_norm': 0.3708462715148926, 'learning_rate': 1.805084745762712e-05, 'epoch': 0.8}\r\n",
      "{'loss': 0.0922, 'grad_norm': 0.29109153151512146, 'learning_rate': 1.796164139161463e-05, 'epoch': 0.8}\r\n",
      "{'loss': 0.0923, 'grad_norm': 0.3556584417819977, 'learning_rate': 1.787243532560214e-05, 'epoch': 0.81}\r\n",
      "{'loss': 0.0929, 'grad_norm': 0.5722259283065796, 'learning_rate': 1.7783229259589654e-05, 'epoch': 0.81}\r\n",
      "{'loss': 0.0918, 'grad_norm': 0.3678278625011444, 'learning_rate': 1.7694023193577162e-05, 'epoch': 0.82}\r\n",
      "{'loss': 0.0916, 'grad_norm': 0.34712475538253784, 'learning_rate': 1.7604817127564674e-05, 'epoch': 0.83}\r\n",
      "{'loss': 0.0928, 'grad_norm': 0.3422374129295349, 'learning_rate': 1.7515611061552186e-05, 'epoch': 0.83}\r\n",
      "{'loss': 0.0885, 'grad_norm': 0.3945304751396179, 'learning_rate': 1.7426404995539697e-05, 'epoch': 0.84}\r\n",
      "{'loss': 0.0937, 'grad_norm': 0.33592501282691956, 'learning_rate': 1.7337198929527206e-05, 'epoch': 0.84}\r\n",
      "{'loss': 0.0937, 'grad_norm': 0.36516696214675903, 'learning_rate': 1.724799286351472e-05, 'epoch': 0.85}\r\n",
      "{'loss': 0.0922, 'grad_norm': 0.3682136833667755, 'learning_rate': 1.715878679750223e-05, 'epoch': 0.86}\r\n",
      "{'loss': 0.0918, 'grad_norm': 0.27776241302490234, 'learning_rate': 1.7069580731489744e-05, 'epoch': 0.86}\r\n",
      "{'loss': 0.0936, 'grad_norm': 0.547401487827301, 'learning_rate': 1.6980374665477252e-05, 'epoch': 0.87}\r\n",
      "{'loss': 0.0923, 'grad_norm': 0.3139157295227051, 'learning_rate': 1.6891168599464764e-05, 'epoch': 0.87}\r\n",
      "{'loss': 0.092, 'grad_norm': 0.33185696601867676, 'learning_rate': 1.68028545941124e-05, 'epoch': 0.88}\r\n",
      "{'loss': 0.0938, 'grad_norm': 0.41096624732017517, 'learning_rate': 1.671364852809991e-05, 'epoch': 0.89}\r\n",
      "{'loss': 0.1014, 'grad_norm': 0.902788519859314, 'learning_rate': 1.6624442462087424e-05, 'epoch': 0.89}\r\n",
      "{'loss': 0.0921, 'grad_norm': 0.3236335515975952, 'learning_rate': 1.6535236396074933e-05, 'epoch': 0.9}\r\n",
      "{'loss': 0.0907, 'grad_norm': 0.29697638750076294, 'learning_rate': 1.6446030330062444e-05, 'epoch': 0.9}\r\n",
      "{'loss': 0.0905, 'grad_norm': 0.27604004740715027, 'learning_rate': 1.6356824264049956e-05, 'epoch': 0.91}\r\n",
      "{'loss': 0.0938, 'grad_norm': 0.40570658445358276, 'learning_rate': 1.6267618198037468e-05, 'epoch': 0.92}\r\n",
      "{'loss': 0.0937, 'grad_norm': 0.40432003140449524, 'learning_rate': 1.617841213202498e-05, 'epoch': 0.92}\r\n",
      "{'loss': 0.0891, 'grad_norm': 0.7909458875656128, 'learning_rate': 1.608920606601249e-05, 'epoch': 0.93}\r\n",
      "{'loss': 0.0934, 'grad_norm': 0.27131614089012146, 'learning_rate': 1.6e-05, 'epoch': 0.93}\r\n",
      "{'loss': 0.095, 'grad_norm': 0.5086100697517395, 'learning_rate': 1.5910793933987514e-05, 'epoch': 0.94}\r\n",
      "{'loss': 0.0878, 'grad_norm': 0.4199938476085663, 'learning_rate': 1.5821587867975023e-05, 'epoch': 0.95}\r\n",
      "{'loss': 0.0921, 'grad_norm': 0.23724892735481262, 'learning_rate': 1.5732381801962534e-05, 'epoch': 0.95}\r\n",
      "{'loss': 0.0933, 'grad_norm': 0.2516151964664459, 'learning_rate': 1.5643175735950046e-05, 'epoch': 0.96}\r\n",
      "{'loss': 0.0926, 'grad_norm': 0.35346755385398865, 'learning_rate': 1.5553969669937558e-05, 'epoch': 0.96}\r\n",
      "{'loss': 0.0922, 'grad_norm': 0.24636703729629517, 'learning_rate': 1.5464763603925066e-05, 'epoch': 0.97}\r\n",
      "{'loss': 0.0879, 'grad_norm': 0.33538663387298584, 'learning_rate': 1.5375557537912577e-05, 'epoch': 0.98}\r\n",
      "{'loss': 0.091, 'grad_norm': 0.3904263973236084, 'learning_rate': 1.528635147190009e-05, 'epoch': 0.98}\r\n",
      "{'loss': 0.0885, 'grad_norm': 0.21449965238571167, 'learning_rate': 1.5197145405887599e-05, 'epoch': 0.99}\r\n",
      "{'loss': 0.0932, 'grad_norm': 0.41362977027893066, 'learning_rate': 1.5107939339875112e-05, 'epoch': 0.99}\r\n",
      "{'loss': 0.0895, 'grad_norm': 0.3025466203689575, 'learning_rate': 1.5018733273862622e-05, 'epoch': 1.0}\r\n",
      "{'loss': 0.0789, 'grad_norm': 0.39311671257019043, 'learning_rate': 1.4929527207850134e-05, 'epoch': 1.01}\r\n",
      "{'loss': 0.0782, 'grad_norm': 0.3108929693698883, 'learning_rate': 1.4840321141837646e-05, 'epoch': 1.01}\r\n",
      "{'loss': 0.0811, 'grad_norm': 0.2677343189716339, 'learning_rate': 1.4751115075825157e-05, 'epoch': 1.02}\r\n",
      "{'loss': 0.0767, 'grad_norm': 0.2481006532907486, 'learning_rate': 1.4661909009812667e-05, 'epoch': 1.02}\r\n",
      "{'loss': 0.0776, 'grad_norm': 0.3623606860637665, 'learning_rate': 1.4573595004460305e-05, 'epoch': 1.03}\r\n",
      "{'loss': 0.0802, 'grad_norm': 0.345173180103302, 'learning_rate': 1.4484388938447816e-05, 'epoch': 1.03}\r\n",
      "{'loss': 0.0787, 'grad_norm': 0.2941950857639313, 'learning_rate': 1.4395182872435324e-05, 'epoch': 1.04}\r\n",
      "{'loss': 0.078, 'grad_norm': 0.31319311261177063, 'learning_rate': 1.4305976806422836e-05, 'epoch': 1.05}\r\n",
      "{'loss': 0.0789, 'grad_norm': 0.43351173400878906, 'learning_rate': 1.4216770740410348e-05, 'epoch': 1.05}\r\n",
      "{'loss': 0.0765, 'grad_norm': 0.41708189249038696, 'learning_rate': 1.412756467439786e-05, 'epoch': 1.06}\r\n",
      "{'loss': 0.0797, 'grad_norm': 0.4445154368877411, 'learning_rate': 1.403835860838537e-05, 'epoch': 1.06}\r\n",
      "{'loss': 0.0799, 'grad_norm': 0.2512166500091553, 'learning_rate': 1.3949152542372881e-05, 'epoch': 1.07}\r\n",
      "{'loss': 0.0764, 'grad_norm': 0.3740565776824951, 'learning_rate': 1.3859946476360393e-05, 'epoch': 1.08}\r\n",
      "{'loss': 0.0794, 'grad_norm': 0.3224373459815979, 'learning_rate': 1.3770740410347903e-05, 'epoch': 1.08}\r\n",
      "{'loss': 0.0808, 'grad_norm': 0.3319285213947296, 'learning_rate': 1.3681534344335414e-05, 'epoch': 1.09}\r\n",
      "{'loss': 0.0804, 'grad_norm': 0.33666250109672546, 'learning_rate': 1.3592328278322926e-05, 'epoch': 1.09}\r\n",
      "{'loss': 0.0797, 'grad_norm': 0.25032225251197815, 'learning_rate': 1.3503122212310438e-05, 'epoch': 1.1}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.37680739164352417, 'learning_rate': 1.3413916146297948e-05, 'epoch': 1.11}\r\n",
      "{'loss': 0.0783, 'grad_norm': 0.310872882604599, 'learning_rate': 1.332471008028546e-05, 'epoch': 1.11}\r\n",
      "{'loss': 0.0769, 'grad_norm': 0.32895615696907043, 'learning_rate': 1.3235504014272971e-05, 'epoch': 1.12}\r\n",
      "{'loss': 0.0774, 'grad_norm': 0.4048561155796051, 'learning_rate': 1.3146297948260483e-05, 'epoch': 1.12}\r\n",
      "{'loss': 0.0808, 'grad_norm': 0.46965688467025757, 'learning_rate': 1.3057091882247992e-05, 'epoch': 1.13}\r\n",
      "{'loss': 0.0798, 'grad_norm': 0.4465111494064331, 'learning_rate': 1.2967885816235504e-05, 'epoch': 1.14}\r\n",
      "{'loss': 0.0771, 'grad_norm': 0.36075708270072937, 'learning_rate': 1.2878679750223016e-05, 'epoch': 1.14}\r\n",
      "{'loss': 0.0772, 'grad_norm': 0.37868842482566833, 'learning_rate': 1.2789473684210526e-05, 'epoch': 1.15}\r\n",
      "{'loss': 0.0754, 'grad_norm': 0.33882370591163635, 'learning_rate': 1.2700267618198037e-05, 'epoch': 1.15}\r\n",
      "{'loss': 0.0801, 'grad_norm': 0.4296448528766632, 'learning_rate': 1.2611061552185549e-05, 'epoch': 1.16}\r\n",
      "{'loss': 0.0784, 'grad_norm': 0.3576677739620209, 'learning_rate': 1.252185548617306e-05, 'epoch': 1.17}\r\n",
      "{'loss': 0.075, 'grad_norm': 0.23453563451766968, 'learning_rate': 1.243264942016057e-05, 'epoch': 1.17}\r\n",
      "{'loss': 0.0763, 'grad_norm': 0.41292282938957214, 'learning_rate': 1.2343443354148082e-05, 'epoch': 1.18}\r\n",
      "{'loss': 0.0782, 'grad_norm': 0.4510310888290405, 'learning_rate': 1.2254237288135594e-05, 'epoch': 1.18}\r\n",
      "{'loss': 0.0795, 'grad_norm': 0.4619876742362976, 'learning_rate': 1.216592328278323e-05, 'epoch': 1.19}\r\n",
      "{'loss': 0.0814, 'grad_norm': 0.43194493651390076, 'learning_rate': 1.2076717216770741e-05, 'epoch': 1.2}\r\n",
      "{'loss': 0.0768, 'grad_norm': 0.39660993218421936, 'learning_rate': 1.1987511150758253e-05, 'epoch': 1.2}\r\n",
      "{'loss': 0.0784, 'grad_norm': 0.36693400144577026, 'learning_rate': 1.1898305084745763e-05, 'epoch': 1.21}\r\n",
      "{'loss': 0.0733, 'grad_norm': 0.46404626965522766, 'learning_rate': 1.1809099018733274e-05, 'epoch': 1.21}\r\n",
      "{'loss': 0.0748, 'grad_norm': 0.2714221179485321, 'learning_rate': 1.1719892952720786e-05, 'epoch': 1.22}\r\n",
      "{'loss': 0.0794, 'grad_norm': 0.21421049535274506, 'learning_rate': 1.1630686886708298e-05, 'epoch': 1.23}\r\n",
      "{'loss': 0.074, 'grad_norm': 0.33298617601394653, 'learning_rate': 1.1541480820695808e-05, 'epoch': 1.23}\r\n",
      "{'loss': 0.0766, 'grad_norm': 0.4396938383579254, 'learning_rate': 1.145227475468332e-05, 'epoch': 1.24}\r\n",
      "{'loss': 0.0781, 'grad_norm': 0.4081341028213501, 'learning_rate': 1.1363068688670831e-05, 'epoch': 1.24}\r\n",
      "{'loss': 0.0789, 'grad_norm': 0.28780436515808105, 'learning_rate': 1.1273862622658341e-05, 'epoch': 1.25}\r\n",
      "{'loss': 0.079, 'grad_norm': 0.38203272223472595, 'learning_rate': 1.1184656556645851e-05, 'epoch': 1.25}\r\n",
      "{'loss': 0.0783, 'grad_norm': 0.31421834230422974, 'learning_rate': 1.1095450490633363e-05, 'epoch': 1.26}\r\n",
      "{'loss': 0.0807, 'grad_norm': 0.38474515080451965, 'learning_rate': 1.1006244424620874e-05, 'epoch': 1.27}\r\n",
      "{'loss': 0.076, 'grad_norm': 0.4250815808773041, 'learning_rate': 1.0917038358608384e-05, 'epoch': 1.27}\r\n",
      "{'loss': 0.077, 'grad_norm': 0.29796722531318665, 'learning_rate': 1.0827832292595896e-05, 'epoch': 1.28}\r\n",
      "{'loss': 0.079, 'grad_norm': 0.3297351896762848, 'learning_rate': 1.0738626226583408e-05, 'epoch': 1.28}\r\n",
      "{'loss': 0.0813, 'grad_norm': 0.665457010269165, 'learning_rate': 1.064942016057092e-05, 'epoch': 1.29}\r\n",
      "{'loss': 0.0763, 'grad_norm': 0.34411510825157166, 'learning_rate': 1.0560214094558429e-05, 'epoch': 1.3}\r\n",
      "{'loss': 0.0802, 'grad_norm': 0.4142453670501709, 'learning_rate': 1.047100802854594e-05, 'epoch': 1.3}\r\n",
      "{'loss': 0.0821, 'grad_norm': 0.3079550564289093, 'learning_rate': 1.0381801962533452e-05, 'epoch': 1.31}\r\n",
      "{'loss': 0.0802, 'grad_norm': 0.4439532160758972, 'learning_rate': 1.0292595896520962e-05, 'epoch': 1.31}\r\n",
      "{'loss': 0.0801, 'grad_norm': 0.32740479707717896, 'learning_rate': 1.0203389830508474e-05, 'epoch': 1.32}\r\n",
      "{'loss': 0.0748, 'grad_norm': 0.4178661108016968, 'learning_rate': 1.0114183764495986e-05, 'epoch': 1.33}\r\n",
      "{'loss': 0.0808, 'grad_norm': 0.39816632866859436, 'learning_rate': 1.0024977698483497e-05, 'epoch': 1.33}\r\n",
      "{'loss': 0.073, 'grad_norm': 0.35908907651901245, 'learning_rate': 9.935771632471007e-06, 'epoch': 1.34}\r\n",
      "{'loss': 0.0749, 'grad_norm': 0.3716711401939392, 'learning_rate': 9.846565566458519e-06, 'epoch': 1.34}\r\n",
      "{'loss': 0.0772, 'grad_norm': 0.41430020332336426, 'learning_rate': 9.75735950044603e-06, 'epoch': 1.35}\r\n",
      "{'loss': 0.0826, 'grad_norm': 0.3713236451148987, 'learning_rate': 9.668153434433542e-06, 'epoch': 1.36}\r\n",
      "{'loss': 0.081, 'grad_norm': 0.30515891313552856, 'learning_rate': 9.578947368421052e-06, 'epoch': 1.36}\r\n",
      "{'loss': 0.0737, 'grad_norm': 0.3343691825866699, 'learning_rate': 9.489741302408564e-06, 'epoch': 1.37}\r\n",
      "{'loss': 0.0757, 'grad_norm': 0.6061510443687439, 'learning_rate': 9.400535236396076e-06, 'epoch': 1.37}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.39125707745552063, 'learning_rate': 9.311329170383585e-06, 'epoch': 1.38}\r\n",
      "{'loss': 0.073, 'grad_norm': 0.24703651666641235, 'learning_rate': 9.222123104371097e-06, 'epoch': 1.39}\r\n",
      "{'loss': 0.0773, 'grad_norm': 0.3523360788822174, 'learning_rate': 9.132917038358609e-06, 'epoch': 1.39}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.43078458309173584, 'learning_rate': 9.04371097234612e-06, 'epoch': 1.4}\r\n",
      "{'loss': 0.0811, 'grad_norm': 0.31948068737983704, 'learning_rate': 8.95450490633363e-06, 'epoch': 1.4}\r\n",
      "{'loss': 0.0755, 'grad_norm': 0.4400579333305359, 'learning_rate': 8.865298840321142e-06, 'epoch': 1.41}\r\n",
      "{'loss': 0.0767, 'grad_norm': 0.29061388969421387, 'learning_rate': 8.776092774308654e-06, 'epoch': 1.42}\r\n",
      "{'loss': 0.0791, 'grad_norm': 0.25508105754852295, 'learning_rate': 8.686886708296164e-06, 'epoch': 1.42}\r\n",
      "{'loss': 0.0745, 'grad_norm': 0.36590859293937683, 'learning_rate': 8.597680642283675e-06, 'epoch': 1.43}\r\n",
      "{'loss': 0.0742, 'grad_norm': 0.2176039069890976, 'learning_rate': 8.508474576271187e-06, 'epoch': 1.43}\r\n",
      "{'loss': 0.079, 'grad_norm': 0.2572226822376251, 'learning_rate': 8.419268510258699e-06, 'epoch': 1.44}\r\n",
      "{'loss': 0.0781, 'grad_norm': 0.30996832251548767, 'learning_rate': 8.330062444246209e-06, 'epoch': 1.45}\r\n",
      "{'loss': 0.079, 'grad_norm': 0.3459559679031372, 'learning_rate': 8.24085637823372e-06, 'epoch': 1.45}\r\n",
      "{'loss': 0.0764, 'grad_norm': 0.9994996190071106, 'learning_rate': 8.151650312221232e-06, 'epoch': 1.46}\r\n",
      "{'loss': 0.0824, 'grad_norm': 0.3240565359592438, 'learning_rate': 8.062444246208744e-06, 'epoch': 1.46}\r\n",
      "{'loss': 0.0772, 'grad_norm': 0.40199485421180725, 'learning_rate': 7.973238180196253e-06, 'epoch': 1.47}\r\n",
      "{'loss': 0.0768, 'grad_norm': 0.28260284662246704, 'learning_rate': 7.884032114183765e-06, 'epoch': 1.47}\r\n",
      "{'loss': 0.0763, 'grad_norm': 0.19357985258102417, 'learning_rate': 7.794826048171277e-06, 'epoch': 1.48}\r\n",
      "{'loss': 0.0803, 'grad_norm': 0.43178150057792664, 'learning_rate': 7.705619982158787e-06, 'epoch': 1.49}\r\n",
      "{'loss': 0.075, 'grad_norm': 0.3330231308937073, 'learning_rate': 7.616413916146298e-06, 'epoch': 1.49}\r\n",
      "{'loss': 0.0742, 'grad_norm': 0.3692304193973541, 'learning_rate': 7.52720785013381e-06, 'epoch': 1.5}\r\n",
      "{'loss': 0.08, 'grad_norm': 0.5212016701698303, 'learning_rate': 7.43800178412132e-06, 'epoch': 1.5}\r\n",
      "{'loss': 0.0786, 'grad_norm': 0.3511646091938019, 'learning_rate': 7.348795718108832e-06, 'epoch': 1.51}\r\n",
      "{'loss': 0.0723, 'grad_norm': 0.3048011362552643, 'learning_rate': 7.2595896520963424e-06, 'epoch': 1.52}\r\n",
      "{'loss': 0.0767, 'grad_norm': 0.27582135796546936, 'learning_rate': 7.170383586083854e-06, 'epoch': 1.52}\r\n",
      "{'loss': 0.0821, 'grad_norm': 0.4032844007015228, 'learning_rate': 7.081177520071365e-06, 'epoch': 1.53}\r\n",
      "{'loss': 0.0778, 'grad_norm': 0.2620949447154999, 'learning_rate': 6.991971454058876e-06, 'epoch': 1.53}\r\n",
      "{'loss': 0.0724, 'grad_norm': 0.41265836358070374, 'learning_rate': 6.902765388046387e-06, 'epoch': 1.54}\r\n",
      "{'loss': 0.0803, 'grad_norm': 0.32981711626052856, 'learning_rate': 6.813559322033898e-06, 'epoch': 1.55}\r\n",
      "{'loss': 0.0796, 'grad_norm': 0.3148983120918274, 'learning_rate': 6.725245316681534e-06, 'epoch': 1.55}\r\n",
      "{'loss': 0.077, 'grad_norm': 0.40301987528800964, 'learning_rate': 6.6360392506690454e-06, 'epoch': 1.56}\r\n",
      "{'loss': 0.0773, 'grad_norm': 0.3267240822315216, 'learning_rate': 6.546833184656556e-06, 'epoch': 1.56}\r\n",
      "{'loss': 0.0747, 'grad_norm': 0.5277836918830872, 'learning_rate': 6.457627118644068e-06, 'epoch': 1.57}\r\n",
      "{'loss': 0.0743, 'grad_norm': 0.3691648542881012, 'learning_rate': 6.368421052631579e-06, 'epoch': 1.58}\r\n",
      "{'loss': 0.0785, 'grad_norm': 0.2803243100643158, 'learning_rate': 6.27921498661909e-06, 'epoch': 1.58}\r\n",
      "{'loss': 0.0745, 'grad_norm': 0.36099475622177124, 'learning_rate': 6.190008920606601e-06, 'epoch': 1.59}\r\n",
      "{'loss': 0.0739, 'grad_norm': 0.28024494647979736, 'learning_rate': 6.100802854594113e-06, 'epoch': 1.59}\r\n",
      "{'loss': 0.0801, 'grad_norm': 0.3411727845668793, 'learning_rate': 6.011596788581624e-06, 'epoch': 1.6}\r\n",
      "{'loss': 0.0757, 'grad_norm': 0.3891202211380005, 'learning_rate': 5.922390722569134e-06, 'epoch': 1.61}\r\n",
      "{'loss': 0.0742, 'grad_norm': 0.36558932065963745, 'learning_rate': 5.833184656556646e-06, 'epoch': 1.61}\r\n",
      "{'loss': 0.0743, 'grad_norm': 0.2630256414413452, 'learning_rate': 5.743978590544157e-06, 'epoch': 1.62}\r\n",
      "{'loss': 0.0749, 'grad_norm': 0.40855562686920166, 'learning_rate': 5.6547725245316685e-06, 'epoch': 1.62}\r\n",
      "{'loss': 0.074, 'grad_norm': 0.4089069664478302, 'learning_rate': 5.565566458519179e-06, 'epoch': 1.63}\r\n",
      "{'loss': 0.0762, 'grad_norm': 0.3533701002597809, 'learning_rate': 5.476360392506691e-06, 'epoch': 1.64}\r\n",
      "{'loss': 0.0745, 'grad_norm': 0.4197433590888977, 'learning_rate': 5.387154326494202e-06, 'epoch': 1.64}\r\n",
      "{'loss': 0.076, 'grad_norm': 0.4049598276615143, 'learning_rate': 5.298840321141837e-06, 'epoch': 1.65}\r\n",
      "{'loss': 0.0746, 'grad_norm': 0.3650645613670349, 'learning_rate': 5.209634255129349e-06, 'epoch': 1.65}\r\n",
      "{'loss': 0.0736, 'grad_norm': 0.43603944778442383, 'learning_rate': 5.12042818911686e-06, 'epoch': 1.66}\r\n",
      "{'loss': 0.078, 'grad_norm': 0.36397266387939453, 'learning_rate': 5.0312221231043715e-06, 'epoch': 1.67}\r\n",
      "{'loss': 0.0793, 'grad_norm': 0.34300217032432556, 'learning_rate': 4.942016057091882e-06, 'epoch': 1.67}\r\n",
      "{'loss': 0.0762, 'grad_norm': 0.42986130714416504, 'learning_rate': 4.852809991079394e-06, 'epoch': 1.68}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.3603236973285675, 'learning_rate': 4.763603925066905e-06, 'epoch': 1.68}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.39061984419822693, 'learning_rate': 4.6743978590544156e-06, 'epoch': 1.69}\r\n",
      "{'loss': 0.0764, 'grad_norm': 0.32385262846946716, 'learning_rate': 4.585191793041927e-06, 'epoch': 1.69}\r\n",
      "{'loss': 0.0782, 'grad_norm': 0.341114342212677, 'learning_rate': 4.495985727029438e-06, 'epoch': 1.7}\r\n",
      "{'loss': 0.0766, 'grad_norm': 0.324405699968338, 'learning_rate': 4.40677966101695e-06, 'epoch': 1.71}\r\n",
      "{'loss': 0.0776, 'grad_norm': 0.432709664106369, 'learning_rate': 4.3175735950044605e-06, 'epoch': 1.71}\r\n",
      "{'loss': 0.0755, 'grad_norm': 0.31137874722480774, 'learning_rate': 4.228367528991972e-06, 'epoch': 1.72}\r\n",
      "{'loss': 0.0787, 'grad_norm': 0.31118419766426086, 'learning_rate': 4.139161462979483e-06, 'epoch': 1.72}\r\n",
      "{'loss': 0.0736, 'grad_norm': 0.35339805483818054, 'learning_rate': 4.0508474576271186e-06, 'epoch': 1.73}\r\n",
      "{'loss': 0.0755, 'grad_norm': 0.37202754616737366, 'learning_rate': 3.96164139161463e-06, 'epoch': 1.74}\r\n",
      "{'loss': 0.0748, 'grad_norm': 0.3476947247982025, 'learning_rate': 3.872435325602141e-06, 'epoch': 1.74}\r\n",
      "{'loss': 0.0776, 'grad_norm': 0.3766897916793823, 'learning_rate': 3.7832292595896522e-06, 'epoch': 1.75}\r\n",
      "{'loss': 0.0781, 'grad_norm': 0.7069918513298035, 'learning_rate': 3.6940231935771635e-06, 'epoch': 1.75}\r\n",
      "{'loss': 0.0774, 'grad_norm': 0.7200731039047241, 'learning_rate': 3.6048171275646747e-06, 'epoch': 1.76}\r\n",
      "{'loss': 0.0778, 'grad_norm': 0.41400521993637085, 'learning_rate': 3.515611061552186e-06, 'epoch': 1.77}\r\n",
      "{'loss': 0.0741, 'grad_norm': 0.23462390899658203, 'learning_rate': 3.426404995539697e-06, 'epoch': 1.77}\r\n",
      "{'loss': 0.083, 'grad_norm': 0.3750167191028595, 'learning_rate': 3.337198929527208e-06, 'epoch': 1.78}\r\n",
      "{'loss': 0.0797, 'grad_norm': 0.562791109085083, 'learning_rate': 3.2479928635147188e-06, 'epoch': 1.78}\r\n",
      "{'loss': 0.0747, 'grad_norm': 0.35353535413742065, 'learning_rate': 3.15878679750223e-06, 'epoch': 1.79}\r\n",
      "{'loss': 0.0728, 'grad_norm': 0.45449960231781006, 'learning_rate': 3.069580731489741e-06, 'epoch': 1.8}\r\n",
      "{'loss': 0.0769, 'grad_norm': 0.425101101398468, 'learning_rate': 2.9803746654772524e-06, 'epoch': 1.8}\r\n",
      "{'loss': 0.0802, 'grad_norm': 0.33408716320991516, 'learning_rate': 2.8911685994647637e-06, 'epoch': 1.81}\r\n",
      "{'loss': 0.0782, 'grad_norm': 0.3991394639015198, 'learning_rate': 2.801962533452275e-06, 'epoch': 1.81}\r\n",
      "{'loss': 0.074, 'grad_norm': 0.3699330687522888, 'learning_rate': 2.712756467439786e-06, 'epoch': 1.82}\r\n",
      "{'loss': 0.079, 'grad_norm': 1.5076680183410645, 'learning_rate': 2.6235504014272973e-06, 'epoch': 1.83}\r\n",
      "{'loss': 0.0766, 'grad_norm': 0.26931068301200867, 'learning_rate': 2.5343443354148086e-06, 'epoch': 1.83}\r\n",
      "{'loss': 0.0788, 'grad_norm': 0.3397577404975891, 'learning_rate': 2.4451382694023194e-06, 'epoch': 1.84}\r\n",
      "{'loss': 0.075, 'grad_norm': 0.2979413866996765, 'learning_rate': 2.3559322033898306e-06, 'epoch': 1.84}\r\n",
      "{'loss': 0.0763, 'grad_norm': 0.2943965196609497, 'learning_rate': 2.2667261373773414e-06, 'epoch': 1.85}\r\n",
      "{'loss': 0.0761, 'grad_norm': 0.28333529829978943, 'learning_rate': 2.1775200713648526e-06, 'epoch': 1.86}\r\n",
      "{'loss': 0.0777, 'grad_norm': 0.4044131934642792, 'learning_rate': 2.088314005352364e-06, 'epoch': 1.86}\r\n",
      "{'loss': 0.0772, 'grad_norm': 0.34749695658683777, 'learning_rate': 1.999107939339875e-06, 'epoch': 1.87}\r\n",
      "{'loss': 0.0758, 'grad_norm': 0.4861719012260437, 'learning_rate': 1.9099018733273863e-06, 'epoch': 1.87}\r\n",
      "{'loss': 0.0745, 'grad_norm': 0.3651428818702698, 'learning_rate': 1.8206958073148973e-06, 'epoch': 1.88}\r\n",
      "{'loss': 0.0747, 'grad_norm': 0.40135160088539124, 'learning_rate': 1.7314897413024086e-06, 'epoch': 1.89}\r\n",
      "{'loss': 0.0748, 'grad_norm': 0.3780555725097656, 'learning_rate': 1.6422836752899198e-06, 'epoch': 1.89}\r\n",
      "{'loss': 0.0747, 'grad_norm': 0.4425811469554901, 'learning_rate': 1.553077609277431e-06, 'epoch': 1.9}\r\n",
      "{'loss': 0.0742, 'grad_norm': 0.313729465007782, 'learning_rate': 1.463871543264942e-06, 'epoch': 1.9}\r\n",
      "{'loss': 0.0728, 'grad_norm': 0.4349403977394104, 'learning_rate': 1.374665477252453e-06, 'epoch': 1.91}\r\n",
      "{'loss': 0.0817, 'grad_norm': 0.9611337780952454, 'learning_rate': 1.2854594112399643e-06, 'epoch': 1.91}\r\n",
      "{'loss': 0.0764, 'grad_norm': 0.3058549463748932, 'learning_rate': 1.1962533452274755e-06, 'epoch': 1.92}\r\n",
      "{'loss': 0.0737, 'grad_norm': 0.7581536769866943, 'learning_rate': 1.1070472792149867e-06, 'epoch': 1.93}\r\n",
      "{'loss': 0.0758, 'grad_norm': 0.22473174333572388, 'learning_rate': 1.017841213202498e-06, 'epoch': 1.93}\r\n",
      "{'loss': 0.0728, 'grad_norm': 0.5706764459609985, 'learning_rate': 9.28635147190009e-07, 'epoch': 1.94}\r\n",
      "{'loss': 0.078, 'grad_norm': 0.3940751254558563, 'learning_rate': 8.394290811775201e-07, 'epoch': 1.94}\r\n",
      "{'loss': 0.0767, 'grad_norm': 0.25865980982780457, 'learning_rate': 7.502230151650312e-07, 'epoch': 1.95}\r\n",
      "{'loss': 0.0758, 'grad_norm': 0.47339460253715515, 'learning_rate': 6.610169491525423e-07, 'epoch': 1.96}\r\n",
      "{'loss': 0.0755, 'grad_norm': 0.36681342124938965, 'learning_rate': 5.718108831400536e-07, 'epoch': 1.96}\r\n",
      "{'loss': 0.0756, 'grad_norm': 0.33550262451171875, 'learning_rate': 4.826048171275646e-07, 'epoch': 1.97}\r\n",
      "{'loss': 0.0756, 'grad_norm': 0.30193156003952026, 'learning_rate': 3.933987511150758e-07, 'epoch': 1.97}\r\n",
      "{'loss': 0.0715, 'grad_norm': 0.3493539094924927, 'learning_rate': 3.04192685102587e-07, 'epoch': 1.98}\r\n",
      "{'loss': 0.0754, 'grad_norm': 0.39281126856803894, 'learning_rate': 2.1498661909009814e-07, 'epoch': 1.99}\r\n",
      "{'loss': 0.0793, 'grad_norm': 0.33911922574043274, 'learning_rate': 1.257805530776093e-07, 'epoch': 1.99}\r\n",
      "{'loss': 0.078, 'grad_norm': 0.4208838939666748, 'learning_rate': 3.657448706512043e-08, 'epoch': 2.0}\r\n",
      "{'train_runtime': 36308.4004, 'train_samples_per_second': 12.967, 'train_steps_per_second': 0.926, 'train_loss': 0.09013124502665791, 'epoch': 2.0}\r\n",
      "100%|██████████████████████████████████| 33630/33630 [10:05:08<00:00,  1.08s/it]\r\n",
      "Uploading...:  94%|████████████████████████▌ | 841M/892M [00:08<00:00, 94.0MB/s]\r\n",
      "Model pushed to: https://huggingface.co/HuyTran1301/codeT5-phase1-ep2-v3\r\n"
     ]
    }
   ],
   "source": [
    "# Bỏ 2 dòng cuối nếu không push lên HuggingFace\n",
    "!python train.py \\\n",
    "  --task denoise \\\n",
    "  --train_file /kaggle/input/denoise-filler-v3/train_denoise.csv \\\n",
    "  --valid_file /kaggle/input/denoise-filler-v3/valid_denoise.csv \\\n",
    "  --output_dir /kaggle/working/denoise/ \\\n",
    "  --init_model Salesforce/codet5-base \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id HuyTran1301/codeT5-phase1-ep2-v3"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7481996,
     "sourceId": 12016862,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7595811,
     "sourceId": 12067646,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36832.500324,
   "end_time": "2025-06-05T23:57:42.875959",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-05T13:43:50.375635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
